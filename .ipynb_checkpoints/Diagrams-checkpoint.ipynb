{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import DataGraph\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import gensim\n",
    "import spacy\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import math\n",
    "import scipy.spatial.distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.tools.set_credentials_file(username='tadas.t', api_key='Ngz5K6kLcZm19NzZxH9b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_clusters(df, dg):\n",
    "    new_clusters = []                               \n",
    "    for cluster in dg.clusters:  \n",
    "        cluster, hom = cluster                                                                  \n",
    "        new_cluster = [df[0][x] for x in cluster]\n",
    "        new_clusters.append((new_cluster, hom[:10]))\n",
    "    return new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOD_TYPES = ['word2vec', 'glove']\n",
    "def get_wordvec(word, model, model_type):\n",
    "    if model_type not in GOOD_TYPES:\n",
    "        raise ValueError('bad model type')\n",
    "    if model_type == 'word2vec':\n",
    "        return model[word]\n",
    "    if model_type == 'glove':\n",
    "        return model(word).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arccosdist_matrix(model, model_type):\n",
    "#     USES ARCCOS-DIST\n",
    "    df = pd.read_csv('/home/tadas/words_smaller.txt')\n",
    "    df = pd.DataFrame(data=list(set(list(df['word']))))\n",
    "\n",
    "    distance_matrix = []\n",
    "\n",
    "    for word in df[0]:\n",
    "        vector = get_wordvec(word, model, model_type)\n",
    "        row = []\n",
    "        for word_2 in df[0]:\n",
    "            if word == word_2:\n",
    "                row.append(0)\n",
    "                continue\n",
    "            vector_2 = get_wordvec(word_2, model, model_type)\n",
    "            distance = math.degrees(np.arccos(1 - dist.cosine(vector, vector_2)))\n",
    "            row.append(distance)\n",
    "        distance_matrix.append(row)\n",
    "\n",
    "    distance_matrix = np.array(distance_matrix)\n",
    "    return df, distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_matrix(model, model_type):\n",
    "#     USES EUCLIDEAN DISTANCE\n",
    "    df = pd.read_csv('/home/tadas/words_smaller.txt')\n",
    "    df = pd.DataFrame(data=list(set(list(df['word']))))\n",
    "\n",
    "    distance_matrix = []\n",
    "\n",
    "    for word in df[0]:\n",
    "        vector = get_wordvec(word, model, model_type)\n",
    "        row = []\n",
    "        for word_2 in df[0]:\n",
    "            if word == word_2:\n",
    "                row.append(0)\n",
    "                continue\n",
    "            vector_2 = get_wordvec(word_2, model, model_type)\n",
    "            distance = np.linalg.norm(vector - vector_2)\n",
    "            row.append(distance)\n",
    "        distance_matrix.append(row)\n",
    "\n",
    "    distance_matrix = np.array(distance_matrix)\n",
    "    return df, distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_data(df, matrix, start, end, step):\n",
    "    cluster_list = []\n",
    "    for epsilon in np.arange(start, end, step):\n",
    "        dg = DataGraph(matrix, epsilon, 300)\n",
    "        print('Started clustering {0}'.format(epsilon))\n",
    "        dg.cluster(report_homology=True)\n",
    "        clusters = get_word_clusters(df, dg)\n",
    "        cluster_list.append(clusters)\n",
    "    return cluster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(cluster_list):\n",
    "    word_y_values = defaultdict(list)\n",
    "    word_homologies = defaultdict(list)\n",
    "\n",
    "    for clusters in cluster_list:\n",
    "        for i, stuff in enumerate(clusters):\n",
    "            cluster, homology = stuff\n",
    "            for word in cluster:\n",
    "                word_y_values[word].append(i)\n",
    "                word_homologies[word].append(homology)\n",
    "    return word_y_values, word_homologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(relevant_words, x_values, word_y_values, word_homologies, filename, title):\n",
    "    data = []\n",
    "    for word in relevant_words:\n",
    "        trace = go.Scatter(\n",
    "            x = x_values,\n",
    "            y = word_y_values[word],\n",
    "            text = [str(x) for x in word_homologies[word]],\n",
    "            name = word,\n",
    "            hoverinfo='text+name'\n",
    "        )\n",
    "        data.append(trace)\n",
    "\n",
    "\n",
    "    layout= go.Layout(\n",
    "        title= title,\n",
    "        hovermode= 'y',\n",
    "        xaxis= dict(\n",
    "            title= 'Angle',\n",
    "            ticklen= 5,\n",
    "            zeroline= False,\n",
    "            gridwidth= 2,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title= 'Words',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2,\n",
    "        ),\n",
    "        showlegend= False\n",
    "    )\n",
    "\n",
    "    fig= go.Figure(data=data, layout=layout)\n",
    "    py.plot(fig, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gensim.models.KeyedVectors.load_word2vec_format('/home/tadas/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "model = spacy.load('en_vectors_glove_md')\n",
    "df, matrix = get_euclidean_matrix(model, model_type='glove')\n",
    "# start = 40\n",
    "# stop = 72\n",
    "# step = 2\n",
    "# cluster_list = produce_data(df, matrix, start, stop, step)\n",
    "# word_y_values, word_homologies = prepare_data(cluster_list)\n",
    "# plot_data(list(range(start,stop,step)), word_y_values, word_homologies, 'word2vec_{0}_{1}_{2}'.format(start, stop, step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started clustering 1.0\n",
      "Started clustering 1.5\n",
      "Started clustering 2.0\n",
      "Started clustering 2.5\n",
      "Started clustering 3.0\n",
      "Started clustering 3.5\n",
      "Started clustering 4.0\n",
      "Started clustering 4.5\n",
      "Started clustering 5.0\n",
      "Started clustering 5.5\n",
      "Started clustering 6.0\n",
      "Started clustering 6.5\n",
      "Started clustering 7.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d3a008551fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcluster_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduce_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mword_y_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_homologies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c9c7f59e2546>\u001b[0m in \u001b[0;36mproduce_data\u001b[0;34m(df, matrix, start, end, step)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Started clustering {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_homology\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcluster_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/applied_topology_project/graph.py\u001b[0m in \u001b[0;36mcluster\u001b[0;34m(self, report_homology)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_homology\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# delete edges with 'false' and then just look for connected components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mhomology_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_isomorphism_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_homology\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m# print(homology_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mgraph_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/applied_topology_project/graph.py\u001b[0m in \u001b[0;36m_get_isomorphism_dict\u001b[0;34m(self, report_homology)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvertex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mlocalhom_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_localhom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mvertex\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0medge\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mlocalhom_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_localhom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/applied_topology_project/graph.py\u001b[0m in \u001b[0;36m_get_localhom\u001b[0;34m(self, simplex)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# for i, operator in enumerate(operators):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# print(i, operator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mbetti_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_betti_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbetti_numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/applied_topology_project/helpers.py\u001b[0m in \u001b[0;36mget_betti_numbers\u001b[0;34m(boundary_operators)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mdim_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mSmith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0msnf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# for it to be over Z_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0msnf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# now we can iterate over columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/applied_topology_project/snf.py\u001b[0m in \u001b[0;36mSmith\u001b[0;34m(M)\u001b[0m\n\u001b[1;32m    101\u001b[0m      \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m      \u001b[0madd_to_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m      \u001b[0madd_to_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mis_lone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_nextentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/applied_topology_project/snf.py\u001b[0m in \u001b[0;36madd_to_column\u001b[0;34m(M, x, k, s)\u001b[0m\n\u001b[1;32m     50\u001b[0m  \u001b[0mnum_righe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_colonne\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mtmpj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_righe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmpj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmpj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchange_sign_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 1\n",
    "stop = 7.5\n",
    "step = 0.5\n",
    "cluster_list = produce_data(df, matrix, start, stop, step)\n",
    "word_y_values, word_homologies = prepare_data(cluster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_words = ['bank',\n",
    "   'thrift',\n",
    "   'depository',\n",
    "   'storehouse',\n",
    "   'cache',\n",
    "   'repository',\n",
    "   'stockpile',\n",
    "   'stash',\n",
    "   'pile',\n",
    "   'bag',\n",
    "   'bottle',\n",
    "   'bin',\n",
    "   'warehouse',\n",
    "   'emporium',\n",
    "   'outlet',\n",
    "   'store',\n",
    "   'showroom',\n",
    "   'manufactory',\n",
    "   'foundry',\n",
    "   'mill',\n",
    "   'depot',\n",
    "   'shop',\n",
    "   'drugstore',\n",
    "   'factory',\n",
    "   'sweatshop',\n",
    "   'branch',\n",
    "   'house',\n",
    "   'barn',\n",
    "   'supermarket',\n",
    "   'mart',\n",
    "   'workroom',\n",
    "   'boutique',\n",
    "   'waste',\n",
    "   'heap',\n",
    "   'pack',\n",
    "   'amass',\n",
    "   'accumulate',\n",
    "   'dissipate',\n",
    "   'cumulate',\n",
    "   'hoard',\n",
    "   'institution',\n",
    "   'organization',\n",
    "   'group',\n",
    "   'treasury',\n",
    "   'deposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(relevant_words, list(range(start,stop,step)), word_y_values, word_homologies, \n",
    "          'glove_{0}_{1}_{2}_finance-euclidean'.format(start, stop, step), \n",
    "          title='Glove finance related words - Euclidean distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
